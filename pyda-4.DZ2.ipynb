{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'visit1': ['Москва', 'Россия']}, {'visit3': ['Владимир', 'Россия']}, {'visit7': ['Тула', 'Россия']}, {'visit8': ['Тула', 'Россия']}, {'visit9': ['Курск', 'Россия']}, {'visit10': ['Архангельск', 'Россия']}]\n",
      "[{'visit1': ['Москва', 'Россия']}, {'visit3': ['Владимир', 'Россия']}, {'visit7': ['Тула', 'Россия']}, {'visit8': ['Тула', 'Россия']}, {'visit9': ['Курск', 'Россия']}, {'visit10': ['Архангельск', 'Россия']}]\n"
     ]
    }
   ],
   "source": [
    "geo_logs = [\n",
    "    {'visit1': ['Москва', 'Россия']},\n",
    "    {'visit2': ['Дели', 'Индия']},\n",
    "    {'visit3': ['Владимир', 'Россия']},\n",
    "    {'visit4': ['Лиссабон', 'Португалия']},\n",
    "    {'visit5': ['Париж', 'Франция']},\n",
    "    {'visit6': ['Лиссабон', 'Португалия']},\n",
    "    {'visit7': ['Тула', 'Россия']},\n",
    "    {'visit8': ['Тула', 'Россия']},\n",
    "    {'visit9': ['Курск', 'Россия']},\n",
    "    {'visit10': ['Архангельск', 'Россия']},\n",
    "]\n",
    "\n",
    "#variant 1\n",
    "filtered_geo_logs = []\n",
    "\n",
    "for d in geo_logs:\n",
    "    for k,v in d.items():\n",
    "        if v[1] == 'Россия':\n",
    "            filtered_geo_logs.append(d)\n",
    "print (filtered_geo_logs)       \n",
    "\n",
    "#variant 2: можно как-то отфильтровать пустые словари и не дублировать кусок скрипта?\n",
    "print([{k:v for (k,v) in i.items() if v[1] == 'Россия'} for i in geo_logs if {k:v for (k,v) in i.items() if v[1] == 'Россия'}!= {}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{98, 35, 15, 213, 54, 119}\n"
     ]
    }
   ],
   "source": [
    "ids = {'user1': [213, 213, 213, 15, 213], 'user2': [54, 54, 119, 119, 119], 'user3': [213, 98, 98, 35]}\n",
    "\n",
    "uniq_geo_id = set()\n",
    "for k,v in ids.items():\n",
    "    for i in v:\n",
    "        uniq_geo_id.add(i)\n",
    "print(uniq_geo_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 слова - 43 %\n",
      "3 слова - 57 %\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "\t'смотреть сериалы онлайн',\n",
    "\t'новости спорта',\n",
    "\t'афиша кино',\n",
    "\t'курс доллара',\n",
    "\t'сериалы этим летом',\n",
    "\t'курс по питону',\n",
    "\t'сериалы про спорт',\n",
    "]\n",
    "\n",
    "words_in_queries = []\n",
    "for i in queries:\n",
    "    words_in_queries.append(i.count(' ')+1)\n",
    "    \n",
    "for i in set(words_in_queries):\n",
    "    print(i, 'слова -', round(words_in_queries.count(i) *100 /len(a)), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yandex'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = {'facebook': 55, 'yandex': 120, 'vk': 115, 'google': 99, 'email': 42, 'aok': 98}\n",
    "sorted(stats.items(), key = lambda x: x[1], reverse=True)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.25\n"
     ]
    }
   ],
   "source": [
    "stream = [\n",
    "    '2018-01-01,user1,3',\n",
    "    '2018-01-07,user1,4',\n",
    "    '2018-03-29,user1,1',\n",
    "    '2018-04-04,user1,13',\n",
    "    '2018-01-05,user2,7',\n",
    "    '2018-06-14,user3,4',\n",
    "    '2018-07-02,user3,10',\n",
    "    '2018-03-21,user4,19',\n",
    "    '2018-03-22,user4,4',\n",
    "    '2018-04-22,user4,8',\n",
    "    '2018-05-03,user4,9',\n",
    "    '2018-05-11,user4,11',\n",
    "]\n",
    "\n",
    "uniq_users = set()\n",
    "count_enters = 0\n",
    "\n",
    "for s in stream:\n",
    "    s.split(',')\n",
    "    count_enters += int(s.split(',')[2])\n",
    "    uniq_users.add(s.split(',')[1])\n",
    "print(count_enters/len(uniq_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25]\n",
      "[1764]\n"
     ]
    }
   ],
   "source": [
    "stats = [\n",
    "    ['2018-01-01', 'google', 25],\n",
    "    ['2018-01-01', 'yandex', 65],\n",
    "    ['2018-01-01', 'market', 89],\n",
    "    ['2018-01-02', 'google', 574],\n",
    "    ['2018-01-02', 'yandex', 249],\n",
    "    ['2018-01-02', 'market', 994],\n",
    "    ['2018-01-03', 'google', 1843],\n",
    "    ['2018-01-03', 'yandex', 1327],\n",
    "    ['2018-01-03', 'market', 1764],\n",
    "]\n",
    "\n",
    "#variant 1\n",
    "#date = '2018-01-01'\n",
    "#company = 'google'\n",
    "#print([ x[2] for x in stats if x[0] == date and x[1] == company ] )\n",
    "\n",
    "#variant 2\n",
    "date_company = ['2018-01-01', 'google']\n",
    "print([x[-1] for x in stats if x[0] == date_company[0] and x[1] == date_company[1]])\n",
    "\n",
    "#common solution\n",
    "filter_list =  ['2018-01-03', 'market']\n",
    "print([x[-1] for x in stats if x[:-1] == filter_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
